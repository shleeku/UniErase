[2025-08-18 11:55:24,186][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-08-18 11:56:38,124][absl][INFO] - Using default tokenizer.
[2025-08-18 11:56:54,883][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2
[2025-08-18 11:57:24,538][absl][INFO] - Using default tokenizer.
[2025-08-18 11:57:29,565][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2
[2025-08-18 11:57:57,329][absl][INFO] - Using default tokenizer.
[2025-08-18 11:58:02,982][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2
[2025-08-18 11:58:55,318][absl][INFO] - Using default tokenizer.
[2025-08-18 11:59:12,215][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2
